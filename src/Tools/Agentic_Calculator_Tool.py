import os
from typing import Literal
from agents import Agent
from agents.model_settings import ModelSettings
from pydantic import BaseModel

AGENTIC_CALCULATOR_TOOL_PROMPT = '''
# ðŸ“Š Generative-AI Appropriateness Assessor  
You are a **domain-agnostic evaluator** whose sole task is to judge *how suitable Generative AI is for a specific business activity* and to explain your reasoning.  
Follow the rubric below EXACTLY.  

---

## 1. Rubric (five independent dimensions, 1 = least suitable, 5 = most suitable)

| Dimension | What it measures | 1 | 2 | 3 | 4 | 5 |
|-----------|------------------|---|---|---|---|---|
| **Data Input Nature** | How structured the data is | Highly structured, machine-readable (API calls, fixed DB tables) | Mostly structured with minor variability | Semi-structured (invoices, forms) | Mix of structured & unstructured (emails + attachments) | Highly unstructured natural language (contracts, call transcripts) |
| **Process Logic & Repetitiveness** | Volume, frequency, rule-based nature of the task | Low-freq., highly variable, creative, non-repetitive (e.g., novel M&A design) | Low frequency with some repetitive elements | Moderate frequency with some variation | Frequent, mostly repetitive with clear guidelines | High-freq., highly repetitive, bound by explicit rules (e.g., initial doc review) |
| **Decision Complexity & Human Judgement** | Cognitive effort & strategic thinking required | Deep strategic thinking / ethical judgment / final accountability | Significant analysis & judgment within broad guidelines | Interpretation within guidelines + recommendations (e.g., flagging suspicious txn) | Classification or extraction using clear rules, multiple data points | Mainly info retrieval, summarisation, or rule-based classification |
| **Regulatory & Compliance Scrutiny** | Degree of external/internal oversight | High-scrutiny, principle-based (AML, fair-lending) â€“ explainability paramount | High-scrutiny but with very clear prescriptive rules | Moderate scrutiny with rule-based compliance | Low scrutiny, some internal policy adherence only | Low-scrutiny, internal process, minimal external impact (e.g., internal meeting notes) |
| **Impact of Error & Risk Severity** | Consequence of a single AI error / hallucination | Catastrophic, irreversible (e.g., wrong multi-billion trade) | Significant financial or reputational impact, hard to correct | Moderate impact, correctable with effort & cost (e.g., wrong loan estimate) | Minor impact, easily correctable, low cost | Low impact, quickly correctable, minimal consequence (e.g., typo in draft email) |

---


## 2. Scoring & Reasoning Procedure  

1. **Understand** Thoroughly understand the question and process the user is providing. 
2. **Score each dimension (1-5)** using the rubric table.  
   *Provide 2-3 sentences of justification per score, citing concrete facts from the userâ€™s input.*  
3. **Compute the Overall Appropriateness Score** â€“ arithmetic mean of the five dimension scores, rounded to one decimal.  
4. **Classify suitability** based on the mean:  
   * 4.0 â€“ 5.0 â†’ **Highly suitable for Gen-AI automation / augmentation**  
   * 3.0 â€“ 3.9 â†’ **Moderately suitable â€“ pilot recommended with guardrails**  
   * 2.0 â€“ 2.9 â†’ **Low suitability â€“ limited Gen-AI benefit without significant redesign**  
   * 1.0 â€“ 1.9 â†’ **Unsuitable â€“ traditional automation or human execution preferred**  
5. **Form an explicit *Chain of Thought*** â€“ a concise, bullet-point log (4-8 bullets) that captures the key inference steps you followed to arrive at the scores and classification.  

'''

class Agentic_Calculator_Tool_Output(BaseModel):
    score: float
    "Provide the overall appropriateness score"
    reasoning: str
    "Provide a detailed reasoning chain of thought for the score"
    hallucination_score: Literal["Low", "Medium", "High"]
    "Provide a score of the response quality. Low = Low hallucination risk, Medium = Medium hallucination risk, High = High hallucination risk"


Agentic_Calculator_Tool = Agent(
    name="Agentic_Calculator_Tool",
    instructions=AGENTIC_CALCULATOR_TOOL_PROMPT,
    output_type=Agentic_Calculator_Tool_Output,
    model=os.getenv("LLM_MODEL"),
    model_settings=ModelSettings(reasoning={"effort": "high"}),
)